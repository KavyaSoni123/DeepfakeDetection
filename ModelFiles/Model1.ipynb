{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we will be implementing Resnext50 and LSTM together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (25.2.10)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (1.70.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl (252.6 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m246.2/252.6 MB\u001b[0m \u001b[31m125.0 kB/s\u001b[0m eta \u001b[36m0:00:52\u001b[0m00:56\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/anaconda3/envs/new_env/lib/python3.11/http/client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/anaconda3/envs/new_env/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/anaconda3/envs/new_env/lib/python3.11/ssl.py\", line 1311, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/anaconda3/envs/new_env/lib/python3.11/ssl.py\", line 1167, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/cli/base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/cli/base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/commands/install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/network/download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_internal/network/utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/Users/kavyasmac/anaconda3/envs/new_env/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/kavyasmac/.local/share/virtualenvs/kavyasmac-wdQCnuT9/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models, applications\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kavyasmac/Desktop/Time Pass/DeepFakeDetection/DeepfakeDetection/ModelFiles'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../CSV Files/train.csv')\n",
    "print(len(train_df))\n",
    "test_df = pd.read_csv('../CSV Files/test.csv')\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                         Video Name   Tag\n",
       "0      0  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "1      1  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "2      2  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "3      3  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "4      4  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Videos to a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the path of a video, resizes its frames for resnext50 and returns a list of frames.\n",
    "IMG_SIZE = 224\n",
    "SEQ_LENGTH = 10  # Number of frames per video\n",
    "NUM_CLASSES = 2 \n",
    "def load_video(path, max_frames=SEQ_LENGTH, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                         Video Name   Tag\n",
       "0      0  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "1      1  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "2      2  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "3      3  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real\n",
       "4      4  /Users/kavyasmac/Desktop/Time Pass/DeepFakeDet...  real"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../CSV Files/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset\n",
    "video_paths = df[\"Video Name\"].values\n",
    "labels = df[\"Tag\"].map({\"real\": 0, \"fake\": 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_paths = test_df[\"Video Name\"].values\n",
    "test_video_labels = test_df[\"Tag\"].map({\"real\": 0, \"fake\": 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video frames\n",
    "X_train = np.array([load_video(path) for path in video_paths])\n",
    "y_train = np.array(labels)\n",
    "X_test = np.array([load_video(path) for path in test_video_paths])\n",
    "y_test = np.array(test_video_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "class DeepfakeModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes, hidden_dim=2048, bidirectional=False):\n",
    "        super(DeepfakeModel, self).__init__()\n",
    "        base_model = applications.ResNeXt50(include_top=False, weights='imagenet')\n",
    "        self.model = models.Sequential(base_model.layers[:-2])  # Feature extractor\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.lstm = layers.Bidirectional(layers.LSTM(hidden_dim, return_sequences=True)) if bidirectional else layers.LSTM(hidden_dim, return_sequences=True)\n",
    "        self.dropout = layers.Dropout(0.4)\n",
    "        self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size, seq_length, h, w, c = tf.shape(x)\n",
    "        x = tf.reshape(x, (batch_size * seq_length, h, w, c))\n",
    "        fmap = self.model(x)  # Feature Extraction\n",
    "        x = self.avgpool(fmap)\n",
    "        x = tf.reshape(x, (batch_size, seq_length, -1))\n",
    "        x_lstm = self.lstm(x)\n",
    "        x_mean = tf.reduce_mean(x_lstm, axis=1)\n",
    "        return fmap, self.dropout(self.fc(x_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api.applications' has no attribute 'ResNeXt50'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mDeepfakeModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mDeepfakeModel.__init__\u001b[39m\u001b[34m(self, num_classes, hidden_dim, bidirectional)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes, hidden_dim=\u001b[32m2048\u001b[39m, bidirectional=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28msuper\u001b[39m(DeepfakeModel, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     base_model = \u001b[43mapplications\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResNeXt50\u001b[49m(include_top=\u001b[38;5;28;01mFalse\u001b[39;00m, weights=\u001b[33m'\u001b[39m\u001b[33mimagenet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = models.Sequential(base_model.layers[:-\u001b[32m2\u001b[39m])  \u001b[38;5;66;03m# Feature extractor\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mself\u001b[39m.avgpool = layers.GlobalAveragePooling2D()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'keras.api.applications' has no attribute 'ResNeXt50'"
     ]
    }
   ],
   "source": [
    "model = DeepfakeModel(NUM_CLASSES)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling DeepfakeModel.call().\n\n\u001b[1m'DeepfakeModel' object has no attribute 'model'\u001b[0m\n\nArguments received by DeepfakeModel.call():\n  • x=tf.Tensor(shape=(None, 10, 224, 224, 3), dtype=uint8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Time Pass/DeepFakeDetection/DeepfakeDetection/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mDeepfakeModel.call\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     33\u001b[39m x = tf.reshape(x, (batch_size * seq_length, h, w, c))\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Extract spatial features using the CNN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m fmap = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m(x)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Apply global average pooling\u001b[39;00m\n\u001b[32m     39\u001b[39m x = \u001b[38;5;28mself\u001b[39m.avgpool(fmap)\n",
      "\u001b[31mAttributeError\u001b[39m: Exception encountered when calling DeepfakeModel.call().\n\n\u001b[1m'DeepfakeModel' object has no attribute 'model'\u001b[0m\n\nArguments received by DeepfakeModel.call():\n  • x=tf.Tensor(shape=(None, 10, 224, 224, 3), dtype=uint8)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, num_classes, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
    "        super(Model, self).__init__()\n",
    "        base_model = applications.ResNeXt50(include_top=False, weights='imagenet')\n",
    "        self.model = models.Sequential(base_model.layers[:-2])\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.lstm = layers.Bidirectional(layers.LSTM(hidden_dim, return_sequences=True)) if bidirectional else layers.LSTM(hidden_dim, return_sequences=True)\n",
    "        self.relu = layers.LeakyReLU()\n",
    "        self.dp = layers.Dropout(0.4)\n",
    "        self.linear1 = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size, seq_length, c, h, w = tf.shape(x)\n",
    "        x = tf.reshape(x, (batch_size * seq_length, h, w, c))\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = tf.reshape(x, (batch_size, seq_length, -1))\n",
    "        x_lstm = self.lstm(x)\n",
    "        x_mean = tf.reduce_mean(x_lstm, axis=1)\n",
    "        return fmap, self.dp(self.linear1(x_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames from a video\n",
    "def extract_frames(video_path, frame_size=(224, 224)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() \n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        frame = img_to_array(frame)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a dataset from the video folders\n",
    "def create_dataset(video_dir, frame_size=(224, 224), seq_length=10):\n",
    "    classes = ['real', 'fake']\n",
    "    data = []\n",
    "    labels = []\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(video_dir, class_name)\n",
    "        for video_name in os.listdir(class_dir):\n",
    "            video_path = os.path.join(class_dir, video_name)\n",
    "            frames = extract_frames(video_path, frame_size)\n",
    "            if len(frames) >= seq_length:\n",
    "                for i in range(0, len(frames) - seq_length + 1, seq_length):\n",
    "                    data.append(frames[i:i + seq_length])\n",
    "                    labels.append(class_idx)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the video folders\n",
    "train_dir = '/Users/kavyasmac/Desktop/Time Pass/DeepFakeDetection/Data/ModelData/Train'\n",
    "\n",
    "# Create the dataset\n",
    "frame_size = (224, 224)\n",
    "seq_length = 10\n",
    "X_train, y_train = create_dataset(train_dir, frame_size, seq_length)\n",
    "\n",
    "# Convert to TensorFlow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(8)\n",
    "\n",
    "# Define the model\n",
    "num_classes = 2\n",
    "model = Model(num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kavyasmac-wdQCnuT9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
