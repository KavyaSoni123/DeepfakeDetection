{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test csv files\n",
    "train_df = pd.read_csv('../CSV Files/train.csv')\n",
    "test_df = pd.read_csv('../CSV Files/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract frames from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = max(1, total_frames // num_frames)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * frame_interval)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (299, 299))\n",
    "        frame = img_to_array(frame) / 255.0\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, num_frames=30):\n",
    "    X, y = [], []\n",
    "    for index, row in df.iterrows():\n",
    "        video_path, label = row['Video Name'], row['Tag']\n",
    "        frames = extract_frames(video_path, num_frames)\n",
    "        if frames.shape[0] == num_frames:\n",
    "            X.append(frames)\n",
    "            y.append(1 if label.lower() == \"fake\" else 0)  \n",
    "    return np.array(X), np.array(y, dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X_train, y_train = prepare_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare testing data\n",
    "X_test,y_test = prepare_dataset(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(30, 299, 299, 3))  # 30 frames of size 299x299x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xception base model for feature extraction\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeDistributed wrapper to apply Xception on each frame\n",
    "x = TimeDistributed(base_model)(input_layer)\n",
    "x = TimeDistributed(GlobalAveragePooling2D())(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layers for sequential analysis\n",
    "x = LSTM(128, return_sequences=True)(x)\n",
    "x = LSTM(64, return_sequences=False)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layers\n",
    "x = Dense(64, activation='relu')(x)\n",
    "out = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = Model(inputs=input_layer, outputs=out)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m997s\u001b[0m 29s/step - accuracy: 0.6303 - loss: 0.6638 - val_accuracy: 0.5735 - val_loss: 0.6932\n",
      "Epoch 2/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m932s\u001b[0m 27s/step - accuracy: 0.5937 - loss: 0.6544 - val_accuracy: 0.4118 - val_loss: 0.9085\n",
      "Epoch 3/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m851s\u001b[0m 25s/step - accuracy: 0.6050 - loss: 0.6515 - val_accuracy: 0.4118 - val_loss: 0.9192\n",
      "Epoch 4/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 24s/step - accuracy: 0.6727 - loss: 0.6049 - val_accuracy: 0.0441 - val_loss: 0.8989\n",
      "Epoch 5/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 24s/step - accuracy: 0.7071 - loss: 0.5577 - val_accuracy: 0.6618 - val_loss: 0.6783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x163a38a90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 66s/step - accuracy: 0.6481 - loss: 0.5758\n",
      "Test Loss: 0.5956, Test Accuracy: 0.6441\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as xception_lstm.keras\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"../Models/xception_lstm.keras\")\n",
    "print(\"Model saved as xception_lstm.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../Models/Xception_LSTM/xception_lstm.keras\", save_format=\"keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
